# ShareGPT4Video: Improving Video Understanding and Generation with Better Captions

⭐️ [**Star to follow our team's projects !**](https://github.com/InternLM/InternLM-XComposer)

---

🚀🚀🚀 Official implementation of **ShareGPT4Video: Improving Video Understanding and Generation with Better Captions**.

Here is an video for introducing ShareGPT4Video clearly:

[![Watch the video](https://img.youtube.com/vi/AQ7j3aegeeI/maxresdefault.jpg)](https://youtu.be/AQ7j3aegeeI)

- **Authors**: [Lin Chen*](https://lin-chen.site), [Xilin Wei*]() [Jinsong Li*](https://li-jinsong.github.io/), [Xiaoyi Dong](https://scholar.google.com/citations?user=FscToE0AAAAJ&hl=en), [Pan Zhang](https://panzhang0212.github.io/), [Yuhang Zang](https://yuhangzang.github.io/), [Zehui Chen](https://lovesnowbest.site/), [Haodong Duan](https://kennymckormick.github.io/), [Bin Lin](https://scholar.google.com.hk/citations?user=GCOVDKoAAAAJ&hl=en), [Zhenyu Tang](), [Li Yuan](https://yuanli2333.github.io/), [Dahua Lin](http://dahua.site/), [Feng Zhao📧](https://scholar.google.com/citations?hl=en&user=r6CvuOUAAAAJ), [Jiaqi Wang 📧](https://myownskyw7.github.io/)
- **Institutes**: University of Science and Technology of China; Shanghai AI Laboratory; Peking University;
- **Resources**: [[Paper]()] [[Project Page](https://sharegpt4video.github.io/)] [[ShareGPT4Video Dataset]()]
- **Models**: [[ShareGPT4Video-8B]()] [[ShareGPT4Video-34B]()] [[ShareCaptioner-Video]()]
- **Demo**: [[🤗ShareGPT4Video-8B]()] [[🤗ShareCaptioner-Video]()]

## 💡 Highlights

- 🔥 A **large-scale** **highly descriptive** video-text dataset, **40K** GPT4-Vision-generated video captions, around **400K** implicit video split captions
- 🔥 A **general video captioner for various video durations, resolutions, aspect ratios**, approaching GPT4-Vision's caption capability, featuring two inference mode targeted for quality and efficiency, separately.
- 🔥 A series of superior large multi-modal models **ShareGPT4Video-8B**, **ShareGPT4Video-34B**, lasting **1 hour** and **5 hours** on 32xA100 GPUs of training respectively.
- 🔥 **Improving Text-to-Video performance** with high-quality video captions generate by our ShareCaptioner-Video

## 📜 News

**[2024/5/26]** The [ShareGPT4Video dataset](https://huggingface.co/datasets/ShareGPT4Video/ShareGPT4Video) and [project page](https://sharegpt4video.github.io/) are released!

## 👨‍💻 Todo

- [ ] Training and evaluation code for ShareGPT4V-8B, ShareGPT4Vidoe-34B
- [ ] Local ShareCaptioner-Video
- [ ] Web demo and local demo of ShareGPT4V-8B
- [ ] Checkpoints of ShareGPT4Vidoe-8B, ShareGPT4Vidoe-34B

## ❤️ Acknowledgments
- [LLaVA](https://github.com/haotian-liu/LLaVA): the codebase we built upon. Thanks for their wonderful work.
- [Open-Sora-Plan](https://github.com/PKU-YuanGroup/Open-Sora-Plan): a excellent open-source codebase for Sora-like text-to-video implementation. Thanks for their wonderful work.
